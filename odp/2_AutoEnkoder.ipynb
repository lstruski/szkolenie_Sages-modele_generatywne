{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd6f7aa",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  Nienadzorowana reprezentacja autoenkodery i modele generatywne\n",
    "</h1>\n",
    "\n",
    "<h4 align=\"center\">\n",
    "  11.10.2023\n",
    "</h4>\n",
    "<br/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4241f9",
   "metadata": {},
   "source": [
    "# Nienadzorowana reprezentacja danych - AutoEnkoder (AE)\n",
    "### Importowanie niezbędnych modułow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a98afc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef7b947",
   "metadata": {},
   "source": [
    "## Prosta implementacja PCA za pomocą warstwy liniowej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28821501",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "mnist = load_digits(n_class=10)\n",
    "x, y = mnist.data, mnist.target\n",
    "\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(x)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(x[idx].reshape((8, 8)), cmap=plt.cm.gray)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "v = pca.transform(x[:10])\n",
    "x_reduced = np.dot(x[:10] - pca.mean_, pca.components_.T)\n",
    "assert np.allclose(v, x_reduced)\n",
    "\n",
    "x_original = np.dot(x_reduced, pca.components_) + pca.mean_\n",
    "assert np.allclose(pca.inverse_transform(v), x_original)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.scatter(*v.T, marker='d', color='b', s=60)\n",
    "# plt.show()\n",
    "# plt.close()\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(x_original[idx].reshape((8, 8)), cmap=plt.cm.gray)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb9bfa7",
   "metadata": {},
   "source": [
    "### PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a49504",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OwnPCA():\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = torch.nn.Linear(input_dim, output_dim, bias=False)\n",
    "        self.dencoder = torch.nn.Linear(output_dim, input_dim, bias=False)\n",
    "        \n",
    "    def set_weight(self, W):\n",
    "        self.encoder.weight.data[...] = torch.from_numpy(W)\n",
    "        self.dencoder.weight.data[...] = torch.from_numpy(W.T)\n",
    "        \n",
    "    def transform(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def inverse_transform(self, x):\n",
    "        return self.dencoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa15ba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_own = OwnPCA(64, 10)\n",
    "pca_own.set_weight(pca.components_)\n",
    "\n",
    "v = pca_own.transform(\n",
    "    torch.from_numpy(\n",
    "        (x[:10] - pca.mean_).astype(np.float32)\n",
    "    )\n",
    ")\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(x[idx].reshape((8, 8)), cmap=plt.cm.gray)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "x_ = pca_own.inverse_transform(v).detach().numpy() + pca.mean_\n",
    "fig, axs = plt.subplots(nrows=1, ncols=10, figsize=(6, 6))\n",
    "for idx, ax in enumerate(axs.ravel()):\n",
    "    ax.imshow(x_[idx].reshape((8, 8)), cmap=plt.cm.gray)\n",
    "    ax.axis(\"off\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32141c8",
   "metadata": {},
   "source": [
    "## Uczenie sieci AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f80337",
   "metadata": {},
   "source": [
    "Klasa ,,*AverageMeter*'' przechowuje oraz przetwarza częściowe wyniki zapisywane w poszczegółnych etapach uczenia modelu. Funkcja ,,*count_parameters*'' zlicza liczbę parametrów sieci, zaś funkcja ,,*show*'' rysuje obrazki ze zbioru danych i ich rekonstrukcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bfbf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=2.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum = self.sum + val * n\n",
    "        self.count = self.count + n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def show(img, recon_img, num_col=None):\n",
    "    if recon_img is None:\n",
    "        rec_images = img\n",
    "    else:\n",
    "        n = img.shape[0]\n",
    "        assert n >= num_col\n",
    "        rec_images = torch.empty((2 * num_col, *img.shape[1:]))\n",
    "        rec_images.data[:num_col] = img.data[:num_col]\n",
    "        rec_images.data[num_col:] = recon_img.data[:num_col]\n",
    "\n",
    "    plt.figure(figsize=[16, 8])\n",
    "    grid = torchvision.utils.make_grid(\n",
    "        rec_images, nrow=num_col, padding=1, normalize=True, scale_each=True\n",
    "    )\n",
    "    np_grid = grid.cpu().numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(np_grid, (1, 2, 0)), interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d48569",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "\n",
    "W tej części przygotowujemy zbiór danych do trenowania i walidacji modelu. Przetwarzamy obrazki ze zbioru *MNIST* do tensorów, które są pobierane iteracyjnie w batchach podczas trenowania sieci (zmienne: ,,*train_loader*'', ,,*test_loader*'')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e0338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../datasets\"\n",
    "download = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root, download=download, train=True, transform=transform\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=False\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root, download=download, train=False, transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=200, shuffle=False, num_workers=4, pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaeae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = train_dataset[1]\n",
    "print(f\"Rozmiar obrazka: {d[0].shape} oraz jego etykieta {d[1]}\")\n",
    "\n",
    "it = iter(train_loader)\n",
    "d = next(it)\n",
    "d[0].shape, d[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4295ec89",
   "metadata": {},
   "source": [
    "Poniżej tworzymy dodatkowe klasy, których będziemy używać do budowy sieci neuronowej (klasa ,,*View*'') jak również do uczenia jej (klasa ,,*LambdaLR*''). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba3e6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(torch.nn.Module):\n",
    "    def __init__(self, *shape) -> None:\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, input_x: torch.Tensor) -> torch.Tensor:\n",
    "        return input_x.view(*self.shape)\n",
    "\n",
    "\n",
    "class LambdaLR(torch.optim.lr_scheduler.LambdaLR):\n",
    "    def __init__(\n",
    "        self, optimizer, lr_lambda, last_epoch=-1, verbose=False, min_val=1e-5\n",
    "    ):\n",
    "        self.min_val = min_val\n",
    "        self.change = True\n",
    "\n",
    "        super(LambdaLR, self).__init__(optimizer, lr_lambda, last_epoch, verbose)\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if self.change:\n",
    "            super().step(epoch)\n",
    "\n",
    "            change = False\n",
    "            values = self.get_last_lr()\n",
    "            for i, data in enumerate(zip(self.optimizer.param_groups, values)):\n",
    "                param_group, lr = data\n",
    "                param_group[\"lr\"] = lr if lr > self.min_val else self.min_val\n",
    "                self.print_lr(self.verbose, i, lr, epoch)\n",
    "\n",
    "            self._last_lr = [group[\"lr\"] for group in self.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2379b6f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "model = torch.nn.Linear(2, 1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "fun = lambda epoch: 0.9 ** epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=fun, last_epoch=-1)\n",
    "\n",
    "epochs = 300\n",
    "lrs = []\n",
    "for i in range(epochs):\n",
    "    optimizer.step()\n",
    "    lrs.append(optimizer.param_groups[0][\"lr\"])\n",
    "    scheduler.step()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(epochs), lrs)\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# ============================================================================\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "scheduler = LambdaLR(optimizer, lr_lambda=fun, min_val=1e-2)\n",
    "\n",
    "epochs = 300\n",
    "lrs = []\n",
    "for i in range(epochs):\n",
    "    optimizer.step()\n",
    "    lrs.append(scheduler.get_last_lr())\n",
    "    scheduler.step()\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(epochs), lrs)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd4d8d9",
   "metadata": {},
   "source": [
    "# AutoEncoder\n",
    "\n",
    "Klasa ,,*AE*'' definuje sieć autoenkodera składająca się z dwóch części: kodującej (enkodera) i dekodującej (dekodera). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e92d4d",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "Napisać kase AE, której części enkoder i dekoder składają się z dwóch warstw fully-connected. Funkcja ,,forward'' powinna zwracać obrazek o rozmiarze (1, 28, 28)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6b9e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, latent_dim, dim_hidden):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(784, dim_hidden)\n",
    "        self.fc2 = torch.nn.Linear(dim_hidden, latent_dim)\n",
    "        \n",
    "        self.fc3 = torch.nn.Linear(latent_dim, dim_hidden)\n",
    "        self.fc4 = torch.nn.Linear(dim_hidden, 784)\n",
    "        \n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        z = self.fc2(x)\n",
    "        out = self.fc3(z)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc4(out)\n",
    "        return z, torch.sigmoid(out).reshape((-1, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1fcefb",
   "metadata": {},
   "source": [
    "[Jak działa wartstwa konwolucyjna?](https://bfirst.tech/konwolucyjne-sieci-neuronowe/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b310e6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, latent_dim: int, dim_hidden: int) -> None:\n",
    "        super(AE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim_h = dim_hidden\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, self.dim_h, 4, 2, 1, bias=False),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(self.dim_h, self.dim_h * 2, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 2),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(self.dim_h * 2, self.dim_h * 4, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 4),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Conv2d(self.dim_h * 4, self.dim_h * 8, 4, 2, 1, bias=False),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 8),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(self.dim_h * (2**3), latent_dim),\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_dim, self.dim_h * 8 * 7 * 7),\n",
    "            torch.nn.ReLU(True),\n",
    "            View(-1, self.dim_h * 8, 7, 7),\n",
    "            torch.nn.ConvTranspose2d(self.dim_h * 8, self.dim_h * 4, 4),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 4),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(self.dim_h * 4, self.dim_h * 2, 4),\n",
    "            torch.nn.BatchNorm2d(self.dim_h * 2),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.ConvTranspose2d(self.dim_h * 2, 1, 4, stride=2),\n",
    "            torch.nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, input_x: torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        z = self.encoder(input_x)\n",
    "        return z, self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61f005",
   "metadata": {},
   "source": [
    "Uczenie modelu i jego walidacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e9963d",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 8\n",
    "dim_hidden = 16\n",
    "\n",
    "model = AE(latent_dim=latent_dim, dim_hidden=dim_hidden)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "use_scheduler = True\n",
    "scheduler = None\n",
    "if use_scheduler:\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 0.8**epoch, min_val=1e-5)\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "scores = {\"train\": {\"loss\": []}, \"test\": {\"loss\": []}}\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    train_tqdm = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    for image, _ in train_tqdm:\n",
    "        image = image.to(device)\n",
    "\n",
    "        _, recon = model(image)\n",
    "        loss = mse_loss(recon, image)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item())\n",
    "\n",
    "        train_tqdm.set_description(f\"TRAIN loss: {losses.val:.4g} ({losses.avg:.4g})\")\n",
    "\n",
    "    scores[\"train\"][\"loss\"].append(losses.avg)\n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    # validating\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_tqdm = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "        for image, _ in eval_tqdm:\n",
    "            image = image.to(device)\n",
    "\n",
    "            _, recon = model(image)\n",
    "            loss = mse_loss(recon, image)\n",
    "\n",
    "            losses.update(loss.item())\n",
    "\n",
    "            eval_tqdm.set_description(f\"TEST loss: {losses.val:.4g} ({losses.avg:.4g})\")\n",
    "\n",
    "    scores[\"test\"][\"loss\"].append(losses.avg)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{epochs}]; \"\n",
    "        f\"train: {scores['train']['loss'][-1]:.4g}; \"\n",
    "        f\"test: {scores['test']['loss'][-1]:.4f}\"\n",
    "        f\"{f'; lr: {scheduler.get_last_lr()[0]:.4g}' if use_scheduler else ''}\"\n",
    "    )\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(), \"ae.pth\"\n",
    ")  # zapisujemy model do dalszej ewaluacji np. obliczenia FID score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e530e5c",
   "metadata": {},
   "source": [
    "Poniżej przedstawiamy zmianę funkcji kosztu sieci AE w trakcie jej uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383faad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "fig = plt.figure(figsize=(22, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(\n",
    "    scores[\"test\"][\"loss\"],\n",
    "    \"r--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Loss na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"train\"][\"loss\"],\n",
    "    \"r-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Loss na zbiorze testowym\",\n",
    ")\n",
    "ax.tick_params(\n",
    "    axis=\"both\",\n",
    "    which=\"both\",\n",
    "    direction=\"out\",\n",
    "    length=6,\n",
    "    width=2,\n",
    "    colors=\"k\",\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "ax.grid(which=\"both\")\n",
    "ax.grid(which=\"major\", color=\"#CCCCCC\", linestyle=\"--\", alpha=0.8)\n",
    "ax.grid(which=\"minor\", color=\"#CCCCCC\", linestyle=\":\", alpha=0.8)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.set_ylabel(\"Losses\")\n",
    "ax.set_xlabel(\"Epoka\")\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b351176",
   "metadata": {},
   "source": [
    "Czas teraz na pokazanie jak wyuczona sieć AE rekonstruuje obrazki ze zbioru MNIST. W tym celu przepuszczamy przez sieć obrazki ze zbioru walidującego (górny wiersz obrazka), a sieć zwraca ich rekonstrukcje (dolny wiersz obrazka).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20bf9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating\n",
    "model.eval()\n",
    "\n",
    "mses = AverageMeter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    eval_tqdm = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n",
    "    for i, (image, _) in eval_tqdm:\n",
    "        image = image.to(device)\n",
    "\n",
    "        _, recon = model(image)\n",
    "        loss = mse_loss(recon, image)\n",
    "\n",
    "        mses.update(loss.item())\n",
    "\n",
    "        eval_tqdm.set_description(f\"mse: {mses.val:.4g} ({mses.avg:.4g})\")\n",
    "\n",
    "        if i == len(test_loader) - 1:\n",
    "            show(image, recon, 10)\n",
    "\n",
    "print(f\"Ewaluation MSE: {mses.avg:.4g}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
