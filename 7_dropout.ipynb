{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8cdefd6",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  Nienadzorowana reprezentacja autoenkodery i modele generatywne\n",
    "</h1>\n",
    "\n",
    "<h4 align=\"center\">\n",
    "  12.10.2023\n",
    "</h4>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "# Techniki regularyzacyjne - [dropout](https://paperswithcode.com/method/dropout)\n",
    "\n",
    "\n",
    "### Importowanie niezbędnych modułow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd6d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7911d6",
   "metadata": {},
   "source": [
    "Klasa ,,*AverageMeter*'' przechowuje oraz przetwarza częściowe wyniki zapisywane w poszczególnych etapach uczenia modelu. Funkcja ,,*accuracy*'' liczy dokładność sieci w procesie uczenia lub jej walidacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb07c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum = self.sum + val * n\n",
    "        self.count = self.count + n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=[1]):\n",
    "    max_k = np.max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    _, pred = output.topk(max_k, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    results = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        results.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a84b1e",
   "metadata": {},
   "source": [
    "W tej części przygotowujemy zbiór danych do trenowania i walidacji modelu. Przetwarzamy obrazki ze zbioru *Cifar-10* do tensorów, które są pobierane iteracyjnie w batchach podczas trenowania sieci (zmienne: ,,*train_loader*'', ,,*test_loader*'')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dfabc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"../datasets\"\n",
    "download = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    ")\n",
    "\n",
    "trainset = datasets.CIFAR10(f\"{root}/cifar10\", train=True, download=download, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "testset = datasets.CIFAR10(f\"{root}/cifar10\", train=False, download=download, transform=transform)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860e3b22",
   "metadata": {},
   "source": [
    "# Model bez regularyzacji dropout \n",
    "\n",
    "Poniżej definujemy klasy *Net*, w której tworzymy sieć neuronową bez regularyzacji *dropout*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf7738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, 3),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Conv2d(32, 64, 3),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Conv2d(64, 128, 3),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b044cbe0",
   "metadata": {},
   "source": [
    "Uczenie modelu i jego walidacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1101f294",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scores = {\n",
    "    \"train\": {\"loss\": [], \"Prec@1\": [], \"Prec@5\": []},\n",
    "    \"test\": {\"loss\": [], \"Prec@1\": [], \"Prec@5\": []},\n",
    "}\n",
    "\n",
    "print(\"The results are described by: (loss, Prec@1, Prec@5)\")\n",
    "epochs = 4\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    train_tqdm = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    for image, target in train_tqdm:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prec1, prec5 = accuracy(torch.softmax(output, dim=1), target, topk=(1, 5))\n",
    "        losses.update(loss.item(), image.shape[0])\n",
    "        top1.update(prec1.item(), image.shape[0])\n",
    "        top5.update(prec5.item(), image.shape[0])\n",
    "\n",
    "        train_tqdm.set_description(\n",
    "            f\"TRAIN [loss, P@1, P@5]: \"\n",
    "            f\"[{losses.val:.4f} ({losses.avg:.4f}),{top1.val:2.2f} \"\n",
    "            f\"({top1.avg:2.2f}),{top5.val:2.2f} ({top5.avg:2.2f})]\"\n",
    "        )\n",
    "\n",
    "    scores[\"train\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"train\"][\"Prec@1\"].append(top1.avg)\n",
    "    scores[\"train\"][\"Prec@5\"].append(top5.avg)\n",
    "\n",
    "    # validating\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_tqdm = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "        for image, target in eval_tqdm:\n",
    "            image, target = image.to(device), target.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            prec1, prec5 = accuracy(torch.softmax(output, dim=1), target, topk=(1, 5))\n",
    "            losses.update(loss.item(), image.shape[0])\n",
    "            top1.update(prec1.item(), image.shape[0])\n",
    "            top5.update(prec5.item(), image.shape[0])\n",
    "\n",
    "            eval_tqdm.set_description(\n",
    "                f\"TEST [loss, P@1, P@5]: \"\n",
    "                f\"[{losses.val:.4f} ({losses.avg:.4f}),{top1.val:2.2f} \"\n",
    "                f\"({top1.avg:2.2f}),{top5.val:2.2f} ({top5.avg:2.2f})]\"\n",
    "            )\n",
    "\n",
    "    scores[\"test\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"test\"][\"Prec@1\"].append(top1.avg)\n",
    "    scores[\"test\"][\"Prec@5\"].append(top5.avg)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{epochs}]\\t\"\n",
    "        f\"train: ({scores['train']['loss'][-1]:.4f},{scores['train']['Prec@1'][-1]:2.2f},\"\n",
    "        f\"{scores['train']['Prec@5'][-1]:2.2f})\\t\"\n",
    "        f\"test: ({scores['test']['loss'][-1]:.4f},{scores['test']['Prec@1'][-1]:2.2f},\"\n",
    "        f\"{scores['test']['Prec@5'][-1]:2.2f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded35bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores['without_dropout'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95fdbdfe",
   "metadata": {},
   "source": [
    "# Model z regularyzacją dropout\n",
    "\n",
    "Poniżej definujemy klasy *Net*, w której tworzymy sieć neuronową z regularyzacją *dropout*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb3d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(3, 32, 3),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Conv2d(32, 64, 3),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Conv2d(64, 128, 3),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(2, 2),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Dropout(0.25),\n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Dropout(0.25),\n",
    "            torch.nn.Linear(256, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7d0c6f",
   "metadata": {},
   "source": [
    "Uczenie modelu i jego walidacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4cd6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scores = {\n",
    "    \"train\": {\"loss\": [], \"Prec@1\": [], \"Prec@5\": []},\n",
    "    \"test\": {\"loss\": [], \"Prec@1\": [], \"Prec@5\": []},\n",
    "}\n",
    "\n",
    "print(\"The results are described by: (loss, Prec@1, Prec@5)\")\n",
    "epochs = 4\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    train_tqdm = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    for image, target in train_tqdm:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prec1, prec5 = accuracy(torch.softmax(output, dim=1), target, topk=(1, 5))\n",
    "        losses.update(loss.item(), image.shape[0])\n",
    "        top1.update(prec1.item(), image.shape[0])\n",
    "        top5.update(prec5.item(), image.shape[0])\n",
    "\n",
    "        train_tqdm.set_description(\n",
    "            f\"TRAIN [loss, P@1, P@5]: \"\n",
    "            f\"[{losses.val:.4f} ({losses.avg:.4f}),{top1.val:2.2f} \"\n",
    "            f\"({top1.avg:2.2f}),{top5.val:2.2f} ({top5.avg:2.2f})]\"\n",
    "        )\n",
    "\n",
    "    scores[\"train\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"train\"][\"Prec@1\"].append(top1.avg)\n",
    "    scores[\"train\"][\"Prec@5\"].append(top5.avg)\n",
    "\n",
    "    # validating\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_tqdm = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "        for image, target in eval_tqdm:\n",
    "            image, target = image.to(device), target.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            prec1, prec5 = accuracy(torch.softmax(output, dim=1), target, topk=(1, 5))\n",
    "            losses.update(loss.item(), image.shape[0])\n",
    "            top1.update(prec1.item(), image.shape[0])\n",
    "            top5.update(prec5.item(), image.shape[0])\n",
    "\n",
    "            eval_tqdm.set_description(\n",
    "                f\"TEST [loss, P@1, P@5]: \"\n",
    "                f\"[{losses.val:.4f} ({losses.avg:.4f}),{top1.val:2.2f} \"\n",
    "                f\"({top1.avg:2.2f}),{top5.val:2.2f} ({top5.avg:2.2f})]\"\n",
    "            )\n",
    "\n",
    "    scores[\"test\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"test\"][\"Prec@1\"].append(top1.avg)\n",
    "    scores[\"test\"][\"Prec@5\"].append(top5.avg)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{epochs}]\\t\"\n",
    "        f\"train: ({scores['train']['loss'][-1]:.4f},{scores['train']['Prec@1'][-1]:2.2f},\"\n",
    "        f\"{scores['train']['Prec@5'][-1]:2.2f})\\t\"\n",
    "        f\"test: ({scores['test']['loss'][-1]:.4f},{scores['test']['Prec@1'][-1]:2.2f},\"\n",
    "        f\"{scores['test']['Prec@5'][-1]:2.2f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda91bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores['with_dropout'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644ffc40",
   "metadata": {},
   "source": [
    "Poniżej przedstawiamy wyniki powyższych dwóch modeli w postaci wykresów. Na pierwszym pokazujemy dokładność modeli w poszczególnych etapach ich uczenia, zaś na drugim wykresie przedstawiamy jak zmienia się funkcja kosztu w czasie ich uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c20e231",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=2.5)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae7f1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prec@1\n",
    "fig = plt.figure(figsize=(22, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(\n",
    "    total_scores[\"without_dropout\"][\"train\"][\"Prec@1\"],\n",
    "    \"g--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Model bez dropout uczony na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"without_dropout\"][\"test\"][\"Prec@1\"],\n",
    "    \"g-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Model bez dropout uczony na zbiorze testowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"with_dropout\"][\"train\"][\"Prec@1\"],\n",
    "    \"b--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Model z dropout uczony na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"with_dropout\"][\"test\"][\"Prec@1\"],\n",
    "    \"b-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Model z dropout uczony na zbiorze testowym\",\n",
    ")\n",
    "ax.tick_params(\n",
    "    axis=\"both\",\n",
    "    which=\"both\",\n",
    "    direction=\"out\",\n",
    "    length=6,\n",
    "    width=2,\n",
    "    colors=\"k\",\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "ax.grid(which=\"both\")\n",
    "ax.grid(which=\"major\", color=\"#CCCCCC\", linestyle=\"--\", alpha=0.8)\n",
    "ax.grid(which=\"minor\", color=\"#CCCCCC\", linestyle=\":\", alpha=0.8)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.set_ylabel(\"ACC (%)\")\n",
    "ax.set_xlabel(\"Epoka\")\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# loss\n",
    "fig = plt.figure(figsize=(22, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(\n",
    "    total_scores[\"without_dropout\"][\"train\"][\"loss\"],\n",
    "    \"g--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Model bez dropout uczony na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"without_dropout\"][\"test\"][\"loss\"],\n",
    "    \"g-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Model bez dropout uczony na zbiorze testowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"with_dropout\"][\"train\"][\"loss\"],\n",
    "    \"b--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Model z dropout uczony na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"with_dropout\"][\"test\"][\"loss\"],\n",
    "    \"b-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Model z dropout uczony na zbiorze testowym\",\n",
    ")\n",
    "ax.tick_params(\n",
    "    axis=\"both\",\n",
    "    which=\"both\",\n",
    "    direction=\"out\",\n",
    "    length=6,\n",
    "    width=2,\n",
    "    colors=\"k\",\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "ax.grid(which=\"both\")\n",
    "ax.grid(which=\"major\", color=\"#CCCCCC\", linestyle=\"--\", alpha=0.8)\n",
    "ax.grid(which=\"minor\", color=\"#CCCCCC\", linestyle=\":\", alpha=0.8)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Epoka\")\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
