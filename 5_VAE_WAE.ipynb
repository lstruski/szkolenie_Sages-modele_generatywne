{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05723d75",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  Nienadzorowana reprezentacja autoenkodery i modele generatywne\n",
    "</h1>\n",
    "\n",
    "<h4 align=\"center\">\n",
    "  11-12.10.2023\n",
    "</h4>\n",
    "<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4057c6",
   "metadata": {},
   "source": [
    "## Porównywanie próbek i rozkładów: MMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4dab30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist, pdist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db3e309",
   "metadata": {},
   "source": [
    "## Zadanie\n",
    "Napisz funkcję liczącą \n",
    "$\n",
    "\\mathrm{MMD}^2_k(X,Y) = \\frac{1}{n(n-1)} \\sum_{i\\neq j}^N k(x_i, x_j) + \\frac{1}{n(n-1)} \\sum_{i\\neq j}^N k(y_i, y_j) - \\frac{2}{n^2} \\sum_{i,j}^N k(x_i, y_j),\n",
    "$\n",
    "gdzie $x_i\\in X$, $y_i\\in Y$, zaś $k(\\cdot, \\cdot)$ jest kernelem. Wygeneruj trzy próbki z rozkładu normalnego w $\\mathbf{R}^2$ o różnych parametrach i policz dla tych próbek metrykę MMD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254ffc1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1a156c9",
   "metadata": {},
   "source": [
    "\n",
    "## Variational AutoEncoder (VAE) i Wasserstein AutoEncoder (WAE).\n",
    "\n",
    "\n",
    "### Importowanie niezbędnych modułow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbec10df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5a42b5",
   "metadata": {},
   "source": [
    "Klasa ,,*AverageMeter*'' przechowuje oraz przetwarza częściowe wyniki zapisywane w poszczegółnych etapach uczenia modelu. Funkcja ,,*count_parameters*'' zlicza liczbę parametrów sieci, zaś funkcja ,,*show*'' rysuje obrazki ze zbioru danych i ich rekonstrukcje."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60584747",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=2.5)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "\n",
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum = self.sum + val * n\n",
    "        self.count = self.count + n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def show(img, recon_img, num_col=None):\n",
    "    if recon_img is None:\n",
    "        rec_images = img\n",
    "    else:\n",
    "        n = img.shape[0]\n",
    "        assert n >= num_col\n",
    "        rec_images = torch.empty((2 * num_col, *img.shape[1:]))\n",
    "        rec_images.data[:num_col] = img.data[:num_col]\n",
    "        rec_images.data[num_col:] = recon_img.data[:num_col]\n",
    "\n",
    "    plt.figure(figsize=[16, 8])\n",
    "    grid = torchvision.utils.make_grid(\n",
    "        rec_images, nrow=num_col, padding=1, normalize=True, scale_each=True\n",
    "    )\n",
    "    np_grid = grid.cpu().numpy()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(np.transpose(np_grid, (1, 2, 0)), interpolation=\"nearest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555c5c84",
   "metadata": {},
   "source": [
    "# Dataloader\n",
    "\n",
    "W tej części przygotowujemy zbiór danych do trenowania i walidacji modelu. Przetwarzamy obrazki ze zbioru *MNIST* do tensorów, które są pobierane iteracyjnie w batchach podczas trenowania sieci (zmienne: ,,*train_loader*'', ,,*test_loader*'')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db002bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/datasets\"\n",
    "download = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"{device=}\")\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(\n",
    "    root, download=download, train=True, transform=transform\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=False\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(\n",
    "    root, download=download, train=False, transform=transform\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=200, shuffle=False, num_workers=4, pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f09549d",
   "metadata": {},
   "source": [
    "Poniżej tworzymy dodatkowe klasy, których będziemy używać do budowy sieci neuronowej (klasa ,,*View*'') jak również do uczenia jej (klasa ,,*LambdaLR*''). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b13f949",
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(torch.nn.Module):\n",
    "    def __init__(self, *shape) -> None:\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "\n",
    "    def forward(self, input_x: torch.Tensor) -> torch.Tensor:\n",
    "        return input_x.view(*self.shape)\n",
    "\n",
    "\n",
    "class LambdaLR(torch.optim.lr_scheduler.LambdaLR):\n",
    "    def __init__(\n",
    "        self, optimizer, lr_lambda, last_epoch=-1, verbose=False, min_val=1e-5\n",
    "    ):\n",
    "        self.min_val = min_val\n",
    "        self.change = True\n",
    "\n",
    "        super(LambdaLR, self).__init__(optimizer, lr_lambda, last_epoch, verbose)\n",
    "\n",
    "    def step(self, epoch=None):\n",
    "        if self.change:\n",
    "            super().step(epoch)\n",
    "\n",
    "            change = False\n",
    "            values = self.get_last_lr()\n",
    "            for i, data in enumerate(zip(self.optimizer.param_groups, values)):\n",
    "                param_group, lr = data\n",
    "                param_group[\"lr\"] = lr if lr > self.min_val else self.min_val\n",
    "                self.print_lr(self.verbose, i, lr, epoch)\n",
    "\n",
    "            self._last_lr = [group[\"lr\"] for group in self.optimizer.param_groups]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e65fa2c",
   "metadata": {},
   "source": [
    "# Wasserstein Autoencoder\n",
    "\n",
    "Klasa ,,*WAE*'' definuje sieć wasserstein autoenkodera składająca się podobnie jak w poprzednich sieciach z dwóch części: kodującej (enkodera) i dekodującej (dekodera). Sieć bazuje na warstwach konwolucyjnych. Jest to kolejny model generatywny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7305b6af",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "Uzupełnij brakujące część sieci, użyj kilku warstw konwolucyjnych. Przestrzeń ukryta powinna być w postaci wektora w $\\mathbf{R}^n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23803a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class WAE(torch.nn.Module):\n",
    "    def __init__(self, latent_dim: int, dim_hidden: int) -> None:\n",
    "        super(WAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim_h = dim_hidden\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            # ???\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            # ???\n",
    "        )\n",
    "\n",
    "    def forward(self, input_x: torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        z = self.encoder(input_x)\n",
    "        return z, self.decoder(z)\n",
    "\n",
    "    def mmd_loss(self, x: torch.Tensor, y: torch.Tensor, sigma: float):\n",
    "        norm_x = x.square().sum(1, keepdim=True)\n",
    "        dist_x = norm_x + norm_x.t() - 2 * torch.mm(x, x.t())\n",
    "\n",
    "        norm_y = y.square().sum(1, keepdim=True)\n",
    "        dist_y = norm_y + norm_y.t() - 2 * torch.mm(y, y.t())\n",
    "\n",
    "        dist = norm_x + norm_y.t() - 2 * torch.mm(x, y.t())\n",
    "\n",
    "        res_1 = sigma / (sigma + dist_x) + sigma / (sigma + dist_y)\n",
    "        res_1 = (1 - torch.eye(x.shape[0]).to(x.device)) * res_1\n",
    "        res_1 = res_1.sum() / (x.shape[0] - 1)\n",
    "        res_2 = sigma / (sigma + dist)\n",
    "        res_2 = res_2.sum() * 2.0 / (x.shape[0])\n",
    "        stats = res_1 - res_2\n",
    "        return stats\n",
    "\n",
    "    def sample(self, num_samples: int, device) -> torch.Tensor:\n",
    "        z = torch.randn(num_samples, self.latent_dim, device=device)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c515a06",
   "metadata": {},
   "source": [
    "Uczenie modelu i jego walidacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81146a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 8\n",
    "dim_hidden = 16\n",
    "\n",
    "model = WAE(latent_dim=latent_dim, dim_hidden=dim_hidden)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "use_scheduler = True\n",
    "scheduler = None\n",
    "if use_scheduler:\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 0.8**epoch, min_val=1e-5)\n",
    "\n",
    "\n",
    "scale = 0.1\n",
    "sigma = 2 * latent_dim * scale\n",
    "C = 2.5\n",
    "\n",
    "mse_loss = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "print(f\"{C=}, {sigma=}\")\n",
    "\n",
    "scores = {\n",
    "    \"train\": {\"loss\": [], \"mse\": [], \"mmd\": []},\n",
    "    \"test\": {\"loss\": [], \"mse\": [], \"mmd\": []},\n",
    "}\n",
    "\n",
    "\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    mses = AverageMeter()\n",
    "    mmds = AverageMeter()\n",
    "\n",
    "    train_tqdm = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    for image, _ in train_tqdm:\n",
    "        image = image.to(device)\n",
    "\n",
    "        z_real, recon = model(image)\n",
    "        z_fake = torch.randn(image.shape[0], latent_dim, device=device)\n",
    "\n",
    "        mmd = model.mmd_loss(z_real, z_fake, sigma)\n",
    "        mmd = mmd / image.shape[0]\n",
    "\n",
    "        mse = mse_loss(recon, image)\n",
    "        loss = mse + C * mmd\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item(), image.shape[0])\n",
    "        mses.update(mse.item(), image.shape[0])\n",
    "        mmds.update(mmd.item(), image.shape[0])\n",
    "\n",
    "        train_tqdm.set_description(\n",
    "            f\"TRAIN [loss, mse]: \"\n",
    "            f\"[{losses.val:.4g} ({losses.avg:.4g}),{mses.val:.4g} ({mses.avg:.4g})]\"\n",
    "        )\n",
    "\n",
    "    scores[\"train\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"train\"][\"mse\"].append(mses.avg)\n",
    "    scores[\"train\"][\"mmd\"].append(mmds.avg)\n",
    "\n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    # validating\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    mses = AverageMeter()\n",
    "    mmds = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_tqdm = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "        for image, _ in eval_tqdm:\n",
    "            image = image.to(device)\n",
    "\n",
    "            z_real, recon = model(image)\n",
    "            z_fake = torch.randn(image.shape[0], latent_dim, device=device)\n",
    "\n",
    "            mmd = model.mmd_loss(z_real, z_fake, sigma)\n",
    "            mmd = mmd / image.shape[0]\n",
    "\n",
    "            mse = mse_loss(recon, image)\n",
    "            loss = mse + C * mmd\n",
    "\n",
    "            losses.update(loss.item(), image.shape[0])\n",
    "            mses.update(mse.item(), image.shape[0])\n",
    "            klds.update(mmd.item(), image.shape[0])\n",
    "\n",
    "            eval_tqdm.set_description(\n",
    "                f\"TEST [loss, mse]: \"\n",
    "                f\"[{losses.val:.4g} ({losses.avg:.4g}),{mses.val:.4g} ({mses.avg:.4g})]\"\n",
    "            )\n",
    "\n",
    "    scores[\"test\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"test\"][\"mse\"].append(mses.avg)\n",
    "    scores[\"test\"][\"mmd\"].append(mmds.avg)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{epochs}]; \"\n",
    "        f\"train: ({scores['train']['loss'][-1]:.4g},{scores['train']['mse'][-1]:.4g},\"\n",
    "        f\"{scores['train']['mmd'][-1]:.4g}); \"\n",
    "        f\"test: ({scores['test']['loss'][-1]:.4f},{scores['test']['mse'][-1]:.4g},\"\n",
    "        f\"{scores['test']['mmd'][-1]:.4g})\"\n",
    "        f\"{f'; lr: {scheduler.get_last_lr()[0]:.4g}' if use_scheduler else ''}\"\n",
    "    )\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(), \"wae.pth\"\n",
    ")  # zapisujemy model do dalszej ewaluacji np. obliczenia FID score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acbdfb0",
   "metadata": {},
   "source": [
    "Poniżej pokazujemy jak przebiega proces uczenia modelu WAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6825b193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "fig = plt.figure(figsize=(22, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(\n",
    "    scores[\"test\"][\"mse\"],\n",
    "    \"g--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"MSE na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"train\"][\"mse\"],\n",
    "    \"g-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"MSE na zbiorze testowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"test\"][\"mmd\"],\n",
    "    \"b--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"MMD na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"train\"][\"mmd\"],\n",
    "    \"b-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"MMD na zbiorze testowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"test\"][\"loss\"],\n",
    "    \"r--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Loss na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"train\"][\"loss\"],\n",
    "    \"r-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Loss na zbiorze testowym\",\n",
    ")\n",
    "ax.tick_params(\n",
    "    axis=\"both\",\n",
    "    which=\"both\",\n",
    "    direction=\"out\",\n",
    "    length=6,\n",
    "    width=2,\n",
    "    colors=\"k\",\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "ax.grid(which=\"both\")\n",
    "ax.grid(which=\"major\", color=\"#CCCCCC\", linestyle=\"--\", alpha=0.8)\n",
    "ax.grid(which=\"minor\", color=\"#CCCCCC\", linestyle=\":\", alpha=0.8)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.set_ylabel(\"Losses\")\n",
    "ax.set_xlabel(\"Epoka\")\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d00060",
   "metadata": {},
   "source": [
    "Poniżej pokazujemy jak wyuczona sieć WAE rekonstruuje obrazki ze zbioru MNIST. W tym celu przepuszczamy przez sieć obrazki ze zbioru walidującego (górny wiersz obrazka), a sieć zwraca ich rekonstrukcje (dolny wiersz obrazka). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa294fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating\n",
    "model.eval()\n",
    "\n",
    "mses = AverageMeter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    eval_tqdm = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n",
    "    for i, (image, _) in eval_tqdm:\n",
    "        image = image.to(device)\n",
    "\n",
    "        latent, recon = model(image)\n",
    "        mse = torch.nn.functional.mse_loss(recon, image)\n",
    "        mses.update(mse.item(), image.shape[0])\n",
    "\n",
    "        eval_tqdm.set_description(f\"mse: {mses.val:.4g} ({mses.avg:.4g})]\")\n",
    "\n",
    "        if i == len(test_loader) - 1:\n",
    "            show(image, recon, 10)\n",
    "\n",
    "print(f\"Ewaluation MSE: {mses.avg:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bb8970",
   "metadata": {},
   "source": [
    "Teraz przestawiamy przykładowe obrazki jakie zostały wygenerowanie poprzez wylosowanie z rozkładu $\\mathcal{N}(0,1)$ kilku wektorów z przestrzeni latent i przepuszczenie ich przez część dekodującą sieci WAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c146811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    imgs = model.sample(20, device)\n",
    "    show(imgs, None, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155f0774",
   "metadata": {},
   "source": [
    "W celu policzenia *FID score* zapiszemy w jednym folderze obrazki pochodzące ze zbioru walidującego MNIST, zaś w drugim folderze losowo generujemy taką samą liczbę obrazków z wyuczonego modelu WAE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4d3de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "\n",
    "total_imgs = 10000\n",
    "\n",
    "\n",
    "Path(\"orig_mnist_test\").mkdir(parents=True, exist_ok=True)\n",
    "if not any(Path(\"orig_mnist_test\").iterdir()):\n",
    "    n = 0\n",
    "    eval_tqdm = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for i, (image, _) in eval_tqdm:\n",
    "        if n >= total_imgs:\n",
    "            break\n",
    "        image = image.to(device)\n",
    "\n",
    "        for i in range(image.shape[0]):\n",
    "            grid = torchvision.utils.make_grid(\n",
    "                image[i], nrow=1, padding=0, normalize=True, scale_each=True\n",
    "            )\n",
    "            np_grid = grid.cpu().numpy()\n",
    "            img = (np.transpose(np_grid, (1, 2, 0)) * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img)\n",
    "            im.save(f\"orig_mnist_test/{n + i}.png\")\n",
    "\n",
    "        n += image.shape[0]\n",
    "\n",
    "\n",
    "Path(\"wae_mnist\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(Path(\"wae_mnist\").iterdir()):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(total_imgs)):\n",
    "            img = model.sample(1, device)\n",
    "\n",
    "            grid = torchvision.utils.make_grid(\n",
    "                img, nrow=1, padding=0, normalize=True, scale_each=True\n",
    "            )\n",
    "            np_grid = grid.cpu().numpy()\n",
    "            img = (np.transpose(np_grid, (1, 2, 0)) * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img)\n",
    "            im.save(f\"wae_mnist/{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a49cb",
   "metadata": {},
   "source": [
    "Teraz policzymy *FID score* podając ścieżki do obrazków oryginalnych i wygenerowanych przez wyuczoną sieć WAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d7d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fid_score\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "num_workers = 4\n",
    "dims = 2048\n",
    "paths = [\"wae_mnist\", \"orig_mnist_test\"]\n",
    "batch_size = 100\n",
    "\n",
    "fid_value = fid_score.calculate_fid_given_paths(\n",
    "    paths, batch_size, device, dims, num_workers\n",
    ")\n",
    "print(\"FID: \", fid_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d4e217",
   "metadata": {},
   "source": [
    "# Variational AutoEncoder\n",
    "\n",
    "Klasa ,,*VAE*'' definuje sieć variational autoenkodera składająca się podobnie jak w sieci AE z dwóch części: kodującej (enkodera) i dekodującej (dekodera). Sieć bazuje na warstwach konwolucyjnych. Model VAE jest przykładowym modelem generatywnym, których sample (losowe obrazki) pochodzą z rozkładu gaussowskiego $\\mathcal{N}(0, 1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4f6ae0",
   "metadata": {},
   "source": [
    "### Zadanie\n",
    "Uzupełnij brakujące części sieci (część enkodującą i dekodującą), użyj kilku warstwy konwolucyjnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a01caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "\n",
    "\n",
    "class VAE(torch.nn.Module):\n",
    "    def __init__(self, latent_dim: int, dim_hidden: int) -> None:\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.latent_dim = latent_dim\n",
    "        self.dim_h = dim_hidden\n",
    "\n",
    "        # Encoder\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            #  ???\n",
    "        )\n",
    "\n",
    "        # Latent\n",
    "        self.mu = torch.nn.Linear(self.dim_h * (2**3), latent_dim)\n",
    "        self.logvar = torch.nn.Linear(self.dim_h * (2**3), latent_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            #  ???\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps * std + mu\n",
    "\n",
    "    def forward(self, input_x: torch.Tensor) -> Tuple[torch.Tensor]:\n",
    "        x = self.encoder(input_x)\n",
    "\n",
    "        mu = self.mu(x)\n",
    "        log_var = self.logvar(x)\n",
    "\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "    def criterion(\n",
    "        self,\n",
    "        recon_x: torch.Tensor,\n",
    "        x: torch.Tensor,\n",
    "        mu: torch.Tensor,\n",
    "        log_var: torch.Tensor,\n",
    "        kld_weight: float = 1,\n",
    "    ) -> torch.Tensor:\n",
    "        BCE = torch.nn.functional.binary_cross_entropy(recon_x, x, reduction=\"sum\")\n",
    "        # BCE = torch.nn.functional.mse_loss(recon_x, x, reduction=\"sum\")\n",
    "\n",
    "        KLD = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n",
    "        return BCE + kld_weight * KLD, BCE, KLD\n",
    "\n",
    "    def sample(self, num_samples: int, device) -> torch.Tensor:\n",
    "        z = torch.randn(num_samples, self.latent_dim, device=device)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4743a9",
   "metadata": {},
   "source": [
    "Uczenie modelu i jego walidacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ab9db4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "latent_dim = 8\n",
    "dim_hidden = 16\n",
    "\n",
    "model = VAE(latent_dim=latent_dim, dim_hidden=dim_hidden)\n",
    "model = model.to(device)\n",
    "print(model)\n",
    "print(f\"Number of parameters: {count_parameters(model)}\")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n",
    "criterion = model.criterion\n",
    "\n",
    "use_scheduler = True\n",
    "scheduler = None\n",
    "if use_scheduler:\n",
    "    scheduler = LambdaLR(optimizer, lr_lambda=lambda epoch: 0.8**epoch, min_val=1e-5)\n",
    "\n",
    "\n",
    "scores = {\n",
    "    \"train\": {\"loss\": [], \"mse\": [], \"kld\": []},\n",
    "    \"test\": {\"loss\": [], \"mse\": [], \"kld\": []},\n",
    "}\n",
    "\n",
    "scale_kld = 2.5\n",
    "epochs = 25\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    mses = AverageMeter()\n",
    "    klds = AverageMeter()\n",
    "\n",
    "    train_tqdm = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    for image, _ in train_tqdm:\n",
    "        image = image.to(device)\n",
    "\n",
    "        recon_batch, mu, log_var = model(image)\n",
    "        loss, bce, kld = criterion(recon_batch, image, mu, log_var, scale_kld)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        losses.update(loss.item(), image.shape[0])\n",
    "        mses.update(bce.item(), image.shape[0])\n",
    "        klds.update(kld.item(), image.shape[0])\n",
    "\n",
    "        train_tqdm.set_description(\n",
    "            f\"TRAIN [loss, mse]: \"\n",
    "            f\"[{losses.val:.4g} ({losses.avg:.4g}),{mses.val:.4g} ({mses.avg:.4g})]\"\n",
    "        )\n",
    "\n",
    "    scores[\"train\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"train\"][\"mse\"].append(mses.avg)\n",
    "    scores[\"train\"][\"kld\"].append(klds.avg)\n",
    "\n",
    "    if use_scheduler:\n",
    "        scheduler.step()\n",
    "\n",
    "    # validating\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    mses = AverageMeter()\n",
    "    klds = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_tqdm = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "        for image, _ in eval_tqdm:\n",
    "            image = image.to(device)\n",
    "\n",
    "            recon_batch, mu, log_var = model(image)\n",
    "            loss, bce, kld = criterion(recon_batch, image, mu, log_var, scale_kld)\n",
    "\n",
    "            losses.update(loss.item(), image.shape[0])\n",
    "            mses.update(bce.item(), image.shape[0])\n",
    "            klds.update(kld.item(), image.shape[0])\n",
    "\n",
    "            eval_tqdm.set_description(\n",
    "                f\"TEST [loss, acc]: \"\n",
    "                f\"[{losses.val:.4g} ({losses.avg:.4g}),{mses.val:.4g} ({mses.avg:.4g})]\"\n",
    "            )\n",
    "\n",
    "    scores[\"test\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"test\"][\"mse\"].append(mses.avg)\n",
    "    scores[\"test\"][\"kld\"].append(klds.avg)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{epochs}]; \"\n",
    "        f\"train: ({scores['train']['loss'][-1]:.4g},{scores['train']['mse'][-1]:.4g},\"\n",
    "        f\"{scores['train']['kld'][-1]:.4g}); \"\n",
    "        f\"test: ({scores['test']['loss'][-1]:.4f},{scores['test']['mse'][-1]:.4g},\"\n",
    "        f\"{scores['test']['kld'][-1]:.4g})\"\n",
    "        f\"{f'; lr: {scheduler.get_last_lr()[0]:.4g}' if use_scheduler else ''}\"\n",
    "    )\n",
    "\n",
    "torch.save(\n",
    "    model.state_dict(), \"vae.pth\"\n",
    ")  # zapisujemy model do dalszej ewaluacji np. obliczenia FID score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71e120",
   "metadata": {},
   "source": [
    "Poniżej pokazujemy jak przebiega proces uczenia modelu VAE w stosunku do częściowych fragmentów funkcji kosztu jak również jej całości."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8824228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "fig = plt.figure(figsize=(22, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(\n",
    "    scores[\"test\"][\"mse\"],\n",
    "    \"g--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"MSE na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"train\"][\"mse\"],\n",
    "    \"g-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"MSE na zbiorze testowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"test\"][\"kld\"],\n",
    "    \"b--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"KLD na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"train\"][\"kld\"],\n",
    "    \"b-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"KLD na zbiorze testowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"test\"][\"loss\"],\n",
    "    \"r--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Loss na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    scores[\"train\"][\"loss\"],\n",
    "    \"r-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"Loss na zbiorze testowym\",\n",
    ")\n",
    "ax.tick_params(\n",
    "    axis=\"both\",\n",
    "    which=\"both\",\n",
    "    direction=\"out\",\n",
    "    length=6,\n",
    "    width=2,\n",
    "    colors=\"k\",\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "ax.grid(which=\"both\")\n",
    "ax.grid(which=\"major\", color=\"#CCCCCC\", linestyle=\"--\", alpha=0.8)\n",
    "ax.grid(which=\"minor\", color=\"#CCCCCC\", linestyle=\":\", alpha=0.8)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.set_ylabel(\"Losses\")\n",
    "ax.set_xlabel(\"Epoka\")\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e8be04",
   "metadata": {},
   "source": [
    "Poniżej pokazujemy jak wyuczona sieć VAE rekonstruuje obrazki ze zbioru MNIST. W tym celu przepuszczamy przez sieć obrazki ze zbioru walidującego (górny wiersz obrazka), a sieć zwraca ich rekonstrukcje (dolny wiersz obrazka).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e611ad5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validating\n",
    "model.eval()\n",
    "\n",
    "mses = AverageMeter()\n",
    "\n",
    "with torch.no_grad():\n",
    "    eval_tqdm = tqdm(enumerate(test_loader), total=len(test_loader), leave=False)\n",
    "    for i, (image, _) in eval_tqdm:\n",
    "        image = image.to(device)\n",
    "\n",
    "        recon_batch, mu, log_var = model(image)\n",
    "        mse = torch.nn.functional.mse_loss(recon_batch, image)\n",
    "        mses.update(mse.item(), image.shape[0])\n",
    "\n",
    "        eval_tqdm.set_description(f\"mse: {mses.val:.4g} ({mses.avg:.4g})]\")\n",
    "\n",
    "        if i == len(test_loader) - 1:\n",
    "            show(image, recon_batch, 10)\n",
    "\n",
    "print(f\"Ewaluation MSE: {mses.avg:.4g}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7efd0bb",
   "metadata": {},
   "source": [
    "Teraz przestawiamy przykładowe obrazki jakie zostały wygenerowanie poprzez wylosowanie z rozkładu $\\mathcal{N}(0, 1)$ kilku wektorów z przestrzeni latent i przepuszczenie ich przez część dekodującą sieci VAE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a179fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generation\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    imgs = model.sample(20, device)\n",
    "    show(imgs, None, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec164fc",
   "metadata": {},
   "source": [
    "W celu policzenia *FID score* zapiszemy w jednym folderze obrazki pochodzące ze zbioru walidującego MNIST, zaś w drugim folderze losowo generujemy taką samą liczbę obrazków z wyuczonego modelu VAE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe04fd2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "total_imgs = 10000\n",
    "\n",
    "\n",
    "Path(\"orig_mnist_test\").mkdir(parents=True, exist_ok=True)\n",
    "if not any(Path(\"orig_mnist_test\").iterdir()):\n",
    "    n = 0\n",
    "    eval_tqdm = tqdm(enumerate(test_loader), total=len(test_loader))\n",
    "    for i, (image, _) in eval_tqdm:\n",
    "        if n >= total_imgs:\n",
    "            break\n",
    "        image = image.to(device)\n",
    "\n",
    "        for i in range(image.shape[0]):\n",
    "            grid = torchvision.utils.make_grid(\n",
    "                image[i], nrow=1, padding=0, normalize=True, scale_each=True\n",
    "            )\n",
    "            np_grid = grid.cpu().numpy()\n",
    "            img = (np.transpose(np_grid, (1, 2, 0)) * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img)\n",
    "            im.save(f\"orig_mnist_test/{n + i}.png\")\n",
    "\n",
    "        n += image.shape[0]\n",
    "\n",
    "\n",
    "Path(\"vae_mnist\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if not any(Path(\"vae_mnist\").iterdir()):\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(total_imgs)):\n",
    "            img = model.sample(1, device)\n",
    "\n",
    "            grid = torchvision.utils.make_grid(\n",
    "                img, nrow=1, padding=0, normalize=True, scale_each=True\n",
    "            )\n",
    "            np_grid = grid.cpu().numpy()\n",
    "            img = (np.transpose(np_grid, (1, 2, 0)) * 255).astype(np.uint8)\n",
    "            im = Image.fromarray(img)\n",
    "            im.save(f\"vae_mnist/{i}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac97495",
   "metadata": {},
   "source": [
    "Teraz policzymy *FID score* podając ścieżki do obrazków oryginalnych i wygenerowanych przez wyuczoną sieć VAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dfb66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fid_score\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "num_workers = 4\n",
    "dims = 2048\n",
    "paths = [\"vae_mnist\", \"orig_mnist_test\"]\n",
    "batch_size = 100\n",
    "\n",
    "fid_value = fid_score.calculate_fid_given_paths(\n",
    "    paths, batch_size, device, dims, num_workers\n",
    ")\n",
    "print(\"FID: \", fid_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
