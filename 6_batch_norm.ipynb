{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45570921",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  Nienadzorowana reprezentacja autoenkodery i modele generatywne\n",
    "</h1>\n",
    "\n",
    "<h4 align=\"center\">\n",
    "  12.10.2023\n",
    "</h4>\n",
    "<br/>\n",
    "\n",
    "\n",
    "\n",
    "## Techniki regularyzacyjne - [batch-norm](https://paperswithcode.com/method/batch-normalization)\n",
    "\n",
    "\n",
    "### Importowanie niezbędnych modułow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "793b30ab",
   "metadata": {},
   "source": [
    "Klasa ,,*AverageMeter*'' przechowuje oraz przetwarza częściowe wyniki zapisywane w poszczególnych etapach uczenia modelu. Funkcja ,,*accuracy*'' liczy dokładność sieci w procesie uczenia lub jej walidacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d068c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum = self.sum + val * n\n",
    "        self.count = self.count + n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=[1]):\n",
    "    max_k = np.max(topk)\n",
    "    batch_size = target.shape[0]\n",
    "\n",
    "    _, pred = output.topk(max_k, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    results = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].reshape(-1).float().sum(0)\n",
    "        results.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a588625",
   "metadata": {},
   "source": [
    "W tej części przygotowujemy zbiór danych do trenowania i walidacji modelu. Przetwarzamy obrazki ze zbioru *Cifar-10* do tensorów, które są pobierane iteracyjnie w batchach podczas trenowania sieci (zmienne: ,,*train_loader*'', ,,*test_loader*'')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722de75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# dataset = 'fmnist'  # Fashion MNIST\n",
    "dataset = \"cifar-10\"\n",
    "root = \"../datasets\"\n",
    "download = True\n",
    "\n",
    "if dataset == \"cifar-10\":\n",
    "    transform = transforms.Compose(\n",
    "        [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "\n",
    "    trainset = datasets.CIFAR10(\n",
    "        root=f\"{root}/cifar10\", train=True, download=download, transform=transform\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        trainset, batch_size=64, shuffle=True, num_workers=2\n",
    "    )\n",
    "\n",
    "    testset = datasets.CIFAR10(\n",
    "        root=f\"{root}/cifar10\", train=False, download=download, transform=transform\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        testset, batch_size=100, shuffle=False, num_workers=2\n",
    "    )\n",
    "elif dataset == \"fmnist\":\n",
    "    transform = transforms.Compose([transforms.Resize(32), transforms.ToTensor()])\n",
    "\n",
    "    train_set = datasets.FashionMNIST(\n",
    "        f\"{root}/fmnist/\", download=download, train=True, transform=transform\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "\n",
    "    test_set = datasets.FashionMNIST(\n",
    "        f\"{root}/fmnist/\", download=download, train=False, transform=transform\n",
    "    )\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=64, shuffle=True)\n",
    "else:\n",
    "    print(\"Choose dataset from: cifar-10, fmnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65c112c",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932bb1d3",
   "metadata": {},
   "source": [
    "# Model LeNet bez regularyzacji *batch-norm*\n",
    "\n",
    "Poniżej definujemy klasy *LeNet5*, w której tworzymy sieć neuronową bez regularyzacji *batch-norm*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00835de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "\n",
    "        self.convolutional_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=1 if dataset == \"fmnist\" else 3,\n",
    "                out_channels=6,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "            ),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=120, out_features=84),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional_layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.linear_layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafac419",
   "metadata": {},
   "source": [
    "Uczenie modelu i jego walidacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c09525f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = LeNet5().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scores = {\n",
    "    \"train\": {\"loss\": [], \"Prec@1\": [], \"Prec@5\": []},\n",
    "    \"test\": {\"loss\": [], \"Prec@1\": [], \"Prec@5\": []},\n",
    "}\n",
    "\n",
    "print(\"The results are described by: (loss, Prec@1, Prec@5)\")\n",
    "epochs = 4\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    train_tqdm = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    for image, target in train_tqdm:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prec1, prec5 = accuracy(torch.softmax(output, dim=1), target, topk=(1, 5))\n",
    "        losses.update(loss.item(), image.shape[0])\n",
    "        top1.update(prec1.item(), image.shape[0])\n",
    "        top5.update(prec5.item(), image.shape[0])\n",
    "\n",
    "        train_tqdm.set_description(\n",
    "            f\"TRAIN [loss, P@1, P@5]: [{losses.val:.4f} ({losses.avg:.4f}),{top1.val:2.2f} \"\n",
    "            f\"({top1.avg:2.2f}),{top5.val:2.2f} ({top5.avg:2.2f})]\"\n",
    "        )\n",
    "\n",
    "    scores[\"train\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"train\"][\"Prec@1\"].append(top1.avg)\n",
    "    scores[\"train\"][\"Prec@5\"].append(top5.avg)\n",
    "\n",
    "    # validating\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_tqdm = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "        for image, target in eval_tqdm:\n",
    "            image, target = image.to(device), target.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            prec1, prec5 = accuracy(torch.softmax(output, dim=1), target, topk=(1, 5))\n",
    "            losses.update(loss.item(), image.shape[0])\n",
    "            top1.update(prec1.item(), image.shape[0])\n",
    "            top5.update(prec5.item(), image.shape[0])\n",
    "\n",
    "            eval_tqdm.set_description(\n",
    "                f\"TEST [loss, P@1, P@5]: [{losses.val:.4f} ({losses.avg:.4f}),{top1.val:2.2f} \"\n",
    "                f\"({top1.avg:2.2f}),{top5.val:2.2f} ({top5.avg:2.2f})]\"\n",
    "            )\n",
    "\n",
    "    scores[\"test\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"test\"][\"Prec@1\"].append(top1.avg)\n",
    "    scores[\"test\"][\"Prec@5\"].append(top5.avg)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{epochs}]\\t\"\n",
    "        f\"train: ({scores['train']['loss'][-1]:.4f},{scores['train']['Prec@1'][-1]:2.2f},\"\n",
    "        f\"{scores['train']['Prec@5'][-1]:2.2f})\\t\"\n",
    "        f\"test: ({scores['test']['loss'][-1]:.4f},{scores['test']['Prec@1'][-1]:2.2f},\"\n",
    "        f\"{scores['test']['Prec@5'][-1]:2.2f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c644cd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores['LeNet5'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b1f4a",
   "metadata": {},
   "source": [
    "# Model LeNet z regularyzacją *batch-norm*\n",
    "\n",
    "Poniżej definujemy klasy *LeNet5_bnorm*, w której tworzymy sieć neuronową z regularyzacją *batch-norm*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a1ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5_bnorm(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5_bnorm, self).__init__()\n",
    "\n",
    "        self.convolutional_layers = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(\n",
    "                in_channels=1 if dataset == \"fmnist\" else 3,\n",
    "                out_channels=6,\n",
    "                kernel_size=5,\n",
    "                stride=1,\n",
    "            ),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            torch.nn.BatchNorm2d(6),\n",
    "            torch.nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            torch.nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1),\n",
    "            torch.nn.ReLU(True),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = torch.nn.Sequential(\n",
    "            torch.nn.Linear(in_features=120, out_features=84),\n",
    "            torch.nn.ReLU(True),\n",
    "            torch.nn.BatchNorm1d(84),\n",
    "            torch.nn.Linear(in_features=84, out_features=10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convolutional_layers(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        return self.linear_layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0339033",
   "metadata": {},
   "source": [
    "Uczenie modelu i jego walidacja."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a32129",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LeNet5_bnorm().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "scores = {\n",
    "    \"train\": {\"loss\": [], \"Prec@1\": [], \"Prec@5\": []},\n",
    "    \"test\": {\"loss\": [], \"Prec@1\": [], \"Prec@5\": []},\n",
    "}\n",
    "\n",
    "print(\"The results are described by: (loss, Prec@1, Prec@5)\")\n",
    "epochs = 4\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    # training\n",
    "    model.train()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    train_tqdm = tqdm(train_loader, total=len(train_loader), leave=False)\n",
    "    for image, target in train_tqdm:\n",
    "        image, target = image.to(device), target.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        prec1, prec5 = accuracy(torch.softmax(output, dim=1), target, topk=(1, 5))\n",
    "        losses.update(loss.item(), image.shape[0])\n",
    "        top1.update(prec1.item(), image.shape[0])\n",
    "        top5.update(prec5.item(), image.shape[0])\n",
    "\n",
    "        train_tqdm.set_description(\n",
    "            f\"TRAIN [loss, P@1, P@5]: \"\n",
    "            f\"[{losses.val:.4f} ({losses.avg:.4f}),{top1.val:2.2f} \"\n",
    "            f\"({top1.avg:2.2f}),{top5.val:2.2f} ({top5.avg:2.2f})]\"\n",
    "        )\n",
    "\n",
    "    scores[\"train\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"train\"][\"Prec@1\"].append(top1.avg)\n",
    "    scores[\"train\"][\"Prec@5\"].append(top5.avg)\n",
    "\n",
    "    # validating\n",
    "    model.eval()\n",
    "\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "    top5 = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        eval_tqdm = tqdm(test_loader, total=len(test_loader), leave=False)\n",
    "        for image, target in eval_tqdm:\n",
    "            image, target = image.to(device), target.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            prec1, prec5 = accuracy(torch.softmax(output, dim=1), target, topk=(1, 5))\n",
    "            losses.update(loss.item(), image.shape[0])\n",
    "            top1.update(prec1.item(), image.shape[0])\n",
    "            top5.update(prec5.item(), image.shape[0])\n",
    "\n",
    "            eval_tqdm.set_description(\n",
    "                f\"TEST [loss, P@1, P@5]: \"\n",
    "                f\"[{losses.val:.4f} ({losses.avg:.4f}),{top1.val:2.2f} \"\n",
    "                f\"({top1.avg:2.2f}),{top5.val:2.2f} ({top5.avg:2.2f})]\"\n",
    "            )\n",
    "\n",
    "    scores[\"test\"][\"loss\"].append(losses.avg)\n",
    "    scores[\"test\"][\"Prec@1\"].append(top1.avg)\n",
    "    scores[\"test\"][\"Prec@5\"].append(top5.avg)\n",
    "\n",
    "    print(\n",
    "        f\"Epoch: [{epoch + 1}/{epochs}]\\t\"\n",
    "        f\"train: ({scores['train']['loss'][-1]:.4f},{scores['train']['Prec@1'][-1]:2.2f},\"\n",
    "        f\"{scores['train']['Prec@5'][-1]:2.2f})\\t\"\n",
    "        f\"test: ({scores['test']['loss'][-1]:.4f},{scores['test']['Prec@1'][-1]:2.2f},\"\n",
    "        f\"{scores['test']['Prec@5'][-1]:2.2f})\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d677f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_scores['LeNet5_bnorm'] = scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8524a",
   "metadata": {},
   "source": [
    "Poniżej przedstawiamy wyniki powyższych dwóch modeli w postaci wykresów. Na pierwszym pokazujemy dokładność modeli w poszczególnych etapach ich uczenia, zaś na drugim wykresie przedstawiamy jak zmienia się funkcja kosztu w czasie ich uczenia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250018c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set(font_scale=2.5)\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3e6dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prec@1\n",
    "fig = plt.figure(figsize=(22, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(\n",
    "    total_scores[\"LeNet5\"][\"train\"][\"Prec@1\"],\n",
    "    \"g--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"LeNet5 uczony na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"LeNet5\"][\"test\"][\"Prec@1\"],\n",
    "    \"g-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"LeNet5 uczony na zbiorze testowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"LeNet5_bnorm\"][\"train\"][\"Prec@1\"],\n",
    "    \"b--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"LeNet5 z batch-norm uczony na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"LeNet5_bnorm\"][\"test\"][\"Prec@1\"],\n",
    "    \"b-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"LeNet5 z batch-norm uczony na zbiorze testowym\",\n",
    ")\n",
    "ax.tick_params(\n",
    "    axis=\"both\",\n",
    "    which=\"both\",\n",
    "    direction=\"out\",\n",
    "    length=6,\n",
    "    width=2,\n",
    "    colors=\"k\",\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "ax.grid(which=\"both\")\n",
    "ax.grid(which=\"major\", color=\"#CCCCCC\", linestyle=\"--\", alpha=0.8)\n",
    "ax.grid(which=\"minor\", color=\"#CCCCCC\", linestyle=\":\", alpha=0.8)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.set_ylabel(\"ACC (%)\")\n",
    "ax.set_xlabel(\"Epoka\")\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "# plt.savefig('./cnn_acc-cifar10.png', bbox_inches='tight')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# loss\n",
    "fig = plt.figure(figsize=(22, 8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(\n",
    "    total_scores[\"LeNet5\"][\"train\"][\"loss\"],\n",
    "    \"g--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"LeNet5 uczony na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"LeNet5\"][\"test\"][\"loss\"],\n",
    "    \"g-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"LeNet5 uczony na zbiorze testowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"LeNet5_bnorm\"][\"train\"][\"loss\"],\n",
    "    \"b--\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"LeNet5 z batch-norm uczony na zbiorze treningowym\",\n",
    ")\n",
    "ax.plot(\n",
    "    total_scores[\"LeNet5_bnorm\"][\"test\"][\"loss\"],\n",
    "    \"b-\",\n",
    "    linewidth=4,\n",
    "    markersize=12,\n",
    "    label=\"LeNet5 z batch-norm uczony na zbiorze testowym\",\n",
    ")\n",
    "ax.tick_params(\n",
    "    axis=\"both\",\n",
    "    which=\"both\",\n",
    "    direction=\"out\",\n",
    "    length=6,\n",
    "    width=2,\n",
    "    colors=\"k\",\n",
    "    grid_alpha=0.5,\n",
    ")\n",
    "ax.grid(which=\"both\")\n",
    "ax.grid(which=\"major\", color=\"#CCCCCC\", linestyle=\"--\", alpha=0.8)\n",
    "ax.grid(which=\"minor\", color=\"#CCCCCC\", linestyle=\":\", alpha=0.8)\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.set_ylabel(\"Loss\")\n",
    "ax.set_xlabel(\"Epoka\")\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1efb337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
